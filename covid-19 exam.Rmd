---
title: "COVID-19 Impact on Exams: A First Glance"
author: "Yuliya Kersha"
output:
  md_document:
    variant: markdown_github
always_allow_html: true
---

```{r setup, echo=FALSE, message = FALSE, warning=FALSE}
knitr::opts_chunk$set(output = "github_document", preview.math = FALSE)
```

# How Did the COVID-19 Pandemic Change Exam Results in the Region?

Please note that the hidden sections contain detailed information about data cleaning and database creation. You may explore these sections if you are really extremely interested in technical details.

## Key Results

* We observe on obtained data an unexpected situation of increased exam results during the pandemic among schools with low socioeconomic status and a decrease in scores among schools with high socioeconomic status. The inequality between schools is therefore reduced due to the pandemic.
* On average, across the overall sample of schools, the pandemic has a relatively weak impact on exam results in the region.



## Preparing individual exam results for the analysis

<details>
  <summary>Open this section</summary>
  
The data type is numeric, and there are no typos or unnecessary characters in the database. There are missing data points for some subjects, but it is not a problem. There are no duplicate records for students in the database.

```{r, echo = FALSE}
library(readxl)
ind_data <- read_excel("ind_data.xlsx", na="NA")

str(ind_data)
sapply(ind_data, function(x) sum(is.na(x)))
sapply(ind_data, function(x) sum(duplicated(x)))
```
To compare exams across different years, we will convert the scores into a percentage of exam completion. This means dividing all values by the maximum score possible for the exam in the particular year. The step is necessary, because the maximum scores vary from year to year. 

```{r, echo = FALSE}
max_scores <- data.frame(year = c(2017, 2018, 2019, 2020, 2021, 2022),
                          rus = c(39, 39, 39, 33, 33, 33),
                          math = c(32, 32, 32, 32, 31, 31))
print(max_scores)
```
```{r, echo = FALSE, message = FALSE}
library(dplyr)
ind_data <- left_join(ind_data, max_scores, by = "year")
ind_data <- ind_data %>%
  mutate(rus_perc = rus.x / rus.y * 100,
         math_perc = math.x / math.y * 100)
```
Let's examine the descriptive statistics. We observe that there is a zero percent completion rate for certain exams. This is suspicious and could indicate the presence of outliers in the data. It is particularly concerning when it comes to the reading exam, where achievements are typically quite high.
```{r, echo = FALSE, message = FALSE, warning=FALSE}
library(tidyr)
ind_data_long <- ind_data %>% 
  select(year, schl_id, stud_id, rus_perc, math_perc) %>%
  pivot_longer(cols = rus_perc:math_perc, names_to = "subject", values_to = "score") %>%
  mutate(subject = case_when(
    subject == "rus_perc" ~ "rus",
    subject == "math_perc" ~ "math",
    TRUE ~ subject))

descriptives <- ind_data_long %>%
  group_by(year, subject) %>%
  summarize(n = sum(!is.na(score)),
            mean = round(mean(score, na.rm = TRUE)), 
            sd = round(sd(score, na.rm = TRUE)), 
            min = round(min(score, na.rm = TRUE)), 
            max = round(max(score, na.rm = TRUE))) %>%
  arrange(factor(subject, levels = c("rus", "math")), year)

library(kableExtra)
kable(descriptives, digits = 0, align = c("l", "l", "c", "c", "c", "c"), col.names = c("Year", "Subject", "N", "Mean", "Std.d.", "Min", "Max")) %>%
  kable_styling(full_width = F) %>%
  pack_rows("Reading", 1, 6) %>%
  pack_rows("Math", 7, 12) %>%
  add_header_above(c("The descriptive statistics for the results of the Unified State Exam
                     in the region from 2017 to 2022"=7))
```
Let's also examine box plots, which can help identify suspicious values in the data. We observe the presence of such values. In reading, despite high average scores, there are suspiciously low values for the exam completion percentage. In mathematics, there are both unusually low and high scores.

```{r, echo = FALSE, message = FALSE, warning=FALSE}
library(ggplot2)
ggplot(ind_data_long[ind_data_long$subject == "rus", ], aes(x = as.factor(year), y = score)) +
  geom_boxplot(fill = "#7cb3e6", alpha=0.8) +
  labs(title = "Distribution of scores in reading from 2017 to 2022", x = "Year", y = "Score")

ggplot(ind_data_long[ind_data_long$subject == "math", ], aes(x = as.factor(year), y = score)) +
  geom_boxplot(fill = "gold1", alpha=0.5) +
  labs(title = "Distribution of scores in mathematics from 2017 to 2022", x = "Year", y = "Score")
```

Now let's use the formal Tukey's method to determine the number of outliers for each subject in each year.

```{r, echo = FALSE, message = FALSE, warning=FALSE}
outlier_counts <- ind_data_long %>%
  group_by(year, subject) %>%
  summarize(n = sum(!is.na(score)),
            outliers = sum(score < quantile(score, 0.25, na.rm = TRUE) - 1.5*IQR(score, na.rm = TRUE) | 
                             score > quantile(score, 0.75, na.rm = TRUE) + 1.5*IQR(score, na.rm = TRUE),
                           na.rm = TRUE))

outlier_counts %>%
  group_by(subject) %>%
  summarize(n=sum(n), outliers=sum(outliers))
```
Overall, we can see that there aren't many of them, considering the total number of observations for each year and subject, so we can remove these data from the database.
```{r, echo = FALSE, message = FALSE, warning=FALSE}
replace_outliers_with_na <- function(x, na.rm = TRUE) {
  qnt <- quantile(x, probs = c(.25, .75), na.rm = na.rm)
  H <- 1.5 * IQR(x, na.rm = na.rm)
  x[x < (qnt[1] - H) | x > (qnt[2] + H)] <- NA
  return(x)}

ind_data_clean <- ind_data_long %>% 
  group_by(year, subject) %>% 
  mutate(score = replace_outliers_with_na(score)) %>% 
  ungroup()
sapply(ind_data_long, function(x) sum(is.na(x)))
sapply(ind_data_clean, function(x) sum(is.na(x)))
```
</details>

## Descriptive analysis of individual exam results

<details>
  <summary>Open this section</summary>

Now let's conduct an initial exploratory data analysis using the percentage of exam completion (0-100) as an indicator of subject achievement, based on data without outliers. We will examine the descriptive statistics by year and subject. From the results, it can be observed that the averages for reading and mathematics decrease after 2019.

```{r, echo = FALSE, message = FALSE, warning=FALSE}
descriptives <- ind_data_clean %>%
  group_by(year, subject) %>%
  summarize(n = sum(!is.na(score)),
            mean = round(mean(score, na.rm = TRUE)), 
            sd = round(sd(score, na.rm = TRUE)), 
            min = round(min(score, na.rm = TRUE)), 
            max = round(max(score, na.rm = TRUE))) %>%
  arrange(factor(subject, levels = c("rus", "math")), year)

kable(descriptives, digits = 0, align = c("l", "c", "c", "c", "c", "c"), col.names = c("Year", "Subject", "N", "Mean", "Std. dev.", "Min", "Max")) %>%
  kable_styling(full_width = F) %>%
  pack_rows("Reading", 1, 6) %>%
  pack_rows("Mathematics", 7, 12) %>%
  add_header_above(c("Descriptive Statistics of Unified State Exam 
                     Results in 2017-2022"=7))
```
Let's also take a look at a graph comparing the distribution of scores in reading and mathematics over a period of 6 years.

* Reading test consistently demontsrates the highest scores regardless of the year of the exam. It is the easiest exam, with a distribution heavily skewed to the left - meaning that more than half of the students score above the average.
* In mathematics, the average percentage of exam completion is generally lower than in reading. The distribution is slightly skewed to the right in the last years. All of this is indicating that the exam is more challenging than the reading exam.

```{r, echo = FALSE, message = FALSE, warning=FALSE}
ggplot(ind_data_clean, aes(x = score, fill = subject)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ year, ncol = 3) +
  labs(title = "The distribution of exam results by subject in each year",
       x = "Score",
       fill = "Subject")
```
For each subject separately, we observe a slight decline in the results in 2020. However, in reading, there seem to be a recovery in the results after 2020, while such a trend is absent in mathematics. It is worth noting nevertheless that these data do not yet provide evidence of a statistically significant effect of the pandemic and only visually illustrate the situation without any control variables.
```{r, echo = FALSE, message = FALSE, warning=FALSE}
ggplot(ind_data_clean[ind_data_clean$subject == "rus", ], aes(x = as.factor(year), y = score)) +
  geom_boxplot(fill = "#7cb3e6", alpha=0.8) +
  labs(title = "The distribution of exam results in reading from 2017 to 2022", x = "Year", y = "Score")

ggplot(ind_data_clean[ind_data_clean$subject == "math", ], aes(x = as.factor(year), y = score)) +
  geom_boxplot(fill = "gold1", alpha=0.5) +
  labs(title = "The distribution of exam results in mathematics from 2017 to 2022", x = "Year", y = "Score")
```
</details>

## Preparing school data for the analysis

<details>
  <summary>Open this section</summary>
  
Let's load the database of school variables from the file. All data in the file are numerical and have been entered without any typos or other symbols. A total of 30 contextual variables have been recorded for schools. From these variables, we need to select several that are substantively meaningful, consistently measured from year to year, and have relatively few missing values. To do this, let's first check the number of missing values in the database for these variables and remove those with a high number of NA.

```{r, echo = FALSE, message = FALSE, warning=FALSE}
schl_data <- read_excel("schl_dat.xlsx", na="NA")
str(schl_data)
summary(schl_data)

schl_data %>%
  group_by(year) %>%
  summarise(n = sum(!is.na(schl_id)),
            across(ses1:ses17, list(miss = ~sum(is.na(.)))))

schl_ses <- select(schl_data, -"ses2", -"ses5", -"ses9", -"ses14", -"ses15", -"ses16", -"ses17")
```

After considering the relatively large number of missing values for several contextual variables, which were eventually removed, the following data remains in the database:

ses1: Proportion of students on the school register
ses3: Proportion of students learning Russian language for less than one year
ses4: Proportion of students with special needs (disabled children)
ses7: Proportion of students with one/both parents unemployed
ses8: Proportion of students with both parents without higher education
ses10: Proportion of students from incomplete families
ses11: Proportion of students from large families
ses12: Proportion of students from socially vulnerable families/leading a deviant lifestyle
ses13: Proportion of students from low-income families

For now we will keep all this variables and create averages for schools from 2017 to 2021 (contextual variables are available only until the year 2021). These new variables will provide an overview of the average socio-economic characteristics of the student population throughout the study period.

```{r, echo = FALSE, message = FALSE, warning=FALSE}
ses_mean <- schl_ses %>%
  group_by(schl_id) %>%
  summarise(across(starts_with("ses"), 
                   list(m = mean, v = var), 
                   na.rm = TRUE))
```

Based on this data, we will identify schools with outliers in the means and variances of context variables, which suggest extreme values and significant changes in their student population over the past 5 years compared to the overall sample. These schools probably had errors in the data collection process, and we will exclude them from the analysis.

```{r, echo = FALSE, message = FALSE, warning=FALSE}
ses_mean_clean <- ses_mean %>% 
  mutate_at(vars(starts_with("ses")), replace_outliers_with_na) %>% 
  ungroup()

library(stringr)
ses_mean_clean <- ses_mean_clean %>%
  mutate(across(ends_with("_m"), ~ ifelse(is.na(get(str_replace(cur_column(), "_m$", "_v"))), NA, .))) %>%
  ungroup()

sapply(ses_mean, function(x) sum(is.na(x)))
sapply(ses_mean_clean, function(x) sum(is.na(x)))
```
</details>

## Descriptive analysis of school context variables

<details>
  <summary>Open this section</summary>

Here are the conclusions that can be drawn from the descriptive statistics table:

* Even after removing data from several schools, there is still sufficient information in the database.
* Schools in the region differ significantly in terms of the proportion of students from families where both parents do not have higher education (on average 65%) and the proportion of students from low-income families (20%).
* There are smaller differences between schools in terms of the proportion of students with disabilities (5,4%), from unemployed families (14%), from incomplete families (22%), from large families (26%) and low-incone families (20%).
* The weakest indicators with low variance and close to zero mean values, are students on internal school records, students studying Russian language for less than a year, and students from socially vulnerable families. There are very few of them in the region's schools. We will exclude this variables from the database.
```{r, echo = FALSE, message = FALSE, warning=FALSE}
ses_mean_clean <- select(ses_mean_clean, -ends_with("v"))

library(vtable)
ses_mean_clean %>%
select(-schl_id) %>%
st(out="kable", summ=c('notNA(x)','mean(x)', 'sd(x)', 'min(x)', 'max(x)'), title="Descriptive Statistics of Average School Data in 2017-2021",
labels=c("ses1: Proportion of students on the school register",
"ses3: Proportion of students learning Russian language for less than one year",
"ses4: Proportion of students with special needs (disabled children)",
"ses7: Proportion of students with one/both parents unemployed",
"ses8: Proportion of students with both parents without higher education",
"ses10: Proportion of students from incomplete families",
"ses11: Proportion of students from large families",
"ses12: Proportion of students from socially vulnerable families/leading a deviant lifestyle",
"ses13: Proportion of students from low-income families")) %>%
  kableExtra::kable_styling()
```

</details>

## Preparing final database for the analysis

<details>
  <summary>Open this section</summary>
  
Now we can merge the individual student data with the school-level context characteristics. Let's examine how the remaining school-level context characteristics in the database are associated with the exam results of the students.

```{r, echo = FALSE, message = FALSE, warning=FALSE}
ses_mean_clean <- select(ses_mean_clean, -"ses1_m", -"ses3_m", -"ses12_m") 
data_ind_level <- merge(ind_data_clean, ses_mean_clean, by = "schl_id")

library(corrplot)
library(Hmisc)

rus <- subset(data_ind_level[, 5:11], data_ind_level$subject == "rus")
corr_r <- cor(rus, use = "pairwise.complete.obs", method="pearson")
testRes = rcorr(as.matrix(rus))
corrplot(corr_r, p.mat = testRes$p, method = "ellipse",
         addCoef.col = "black",
         number.cex = 0.75, sig.level = 0.05,
         tl.col = "black", title="Reading")

math <- subset(data_ind_level[, 5:11], data_ind_level$subject == "math")
corr_m <- cor(math, use = "pairwise.complete.obs", method="pearson")
testRes <- rcorr(as.matrix(math))
corrplot(corr_m, p.mat = testRes$p, method = "ellipse",
         addCoef.col = "black", sig.level = 0.05,
         number.cex = 0.75,
         tl.col = "black", title="Mathematics")


```
Based on the plot, the strongest correlation (and it's negative) with exam results shows the proportion of students from families where both parents do not have a higher education. Besides, this variable is strongly correlated with other student population characteristics. According to theory and our previous research findings, this specific variable is the most meaningful and substantively relevant. Therefore, in the future models, we will include only this one variable as a control characteristic of schools context.

</details>

## The impact of the COVID-19 pandemic on exam results
  
To answer the main research question - how the COVID-19 pandemic has affected the quality of the Unified State Exam (USE) results in the region - I will employ multilevel regression modeling. The models will account for a three-level structure of the data, with students at the first level, the year of examination at the second level, and schools at the third level. At the school level, one contextual characteristic will be controlled as a proxy for socioeconomic status (SES): the proportion of children from families where both parents lack higher education averaged for the period from 2017 to 2021.

For each subject, two regression models will be constructed. The first model will estimate the differences in results between the years of study for the entire sample, without assuming a differential effect of the pandemic. In the second model, the interaction variable will be included, and the differences in results between the years will be estimated for schools with different levels of contextual variable. The random intercept and fixed slope model is used, demonstrating the best fit to the data. 

```{r, echo = FALSE, message = FALSE, warning=FALSE}
library(sjstats)
library(sjPlot)
library(dplyr)

ses_mean_clean <- mutate(ses_mean_clean, ses8_std = scale(ses8_m))
data_ind_level <- inner_join(data_ind_level, ses_mean_clean %>% 
                                 select(schl_id, ses8_std), by = "schl_id")
data_ind_level <- data_ind_level  %>% 
  group_by(year, subject) %>%
  mutate(score_std = scale(score))
data_ind_level$year_f <- relevel(as.factor(data_ind_level$year), ref="2020")

library(lme4)
library(ggeffects)
library(ggplot2)

rus_mod1 <- lmer(score_std ~ 1 + year_f + ses8_std + (1 | schl_id/year), data = data_ind_level, subset = subject == "rus")
rus_mod2 <- lmer(score_std ~ 1 + year_f*ses8_std + (1 | schl_id/year), data = data_ind_level, subset = subject == "rus")

math_mod1 <- lmer(score_std ~ 1 + year_f + ses8_std + (1 | schl_id/year), data = data_ind_level, subset = subject == "math")
math_mod2 <- lmer(score_std ~ 1 + year_f*ses8_std + (1 | schl_id/year), data = data_ind_level, subset = subject == "math")
```

In the models below, exam results for different years are compared to the reference year of 2020, when students were required to learn remotely for part of the academic year. The data obtained reveals interesting patterns. When considering the overall sample without the interaction variable, the exam results for all years are nearly identical. Although there is a statistically significant increase in math scores after the pandemic, the effect size is so small that it is difficult to argue for a real improvement compared to previous years. In other words, on average, the exam results in the region did not change due to the COVID-19 pandemic.

```{r, echo = FALSE, message = FALSE, warning=FALSE}
tab_model(rus_mod1, rus_mod2, math_mod1, math_mod2, dv.labels = c("Reading", "Reading (with interaction)", "Mathematics", "Mathematics (with interaction)"), show.aic = TRUE, show.aicc = TRUE, show.loglik = TRUE)
```

However, when the interaction variable is included in the model, significant differences emerge in how exam scores changed in 2020 among different groups of schools. To ease the interpretation of these models, we will refer to the visualization of predicted values.

```{r, echo=FALSE, fig.cap="Predicted scores for reading in schools with different SES"}
rus_pl <- ggpredict(rus_mod2, c("year_f", "ses8_std"))
plot(rus_pl, ci = TRUE, connect.lines = TRUE)+
  labs(title = "Predicted scores for reading in schools with different SES", color="SES", x="Year", y="Exam score")+
  scale_colour_brewer(palette = "Set1" , labels = c("High-SES", "Middle-SES", "Low-SES"))
```

```{r, echo=FALSE, fig.cap="Predicted scores for mathematics in schools with different SES"}
math_pl <- ggpredict(math_mod2, c("year_f", "ses8_std"))
plot(math_pl, ci = TRUE, connect.lines = TRUE)+
  labs(title = "Predicted scores for mathematics in schools with different SES", color="SES", x="Year", y="Exam score")+
  scale_colour_brewer(palette = "Set1" , labels = c("High-SES", "Middle-SES", "Low-SES"))
```

Surprisingly, in 2020, the most affluent schools (with low proportion of children from families without higher education) experienced a considerable decline in exam scores compared to previous years, while schools with low socioeconomic status demonstrated an increase. These findings suggest that the pandemic had a varying impact on schools based on their socioeconomic conditions.

These results contradict findings from international studies, which often demonstrate the opposite situation, namely an exacerbation of inequality during the pandemic. However, on Russian data, we previously observed a widespread decrease in scores regardless of school SES, that is without an increase in inequality. On this data, we notice a significant reduction in the achievement gap between schools with different contexts in the pandemic year. After 2020, there is some return to the pre-pandemic situation, especially in reading scores, but it is not significant.

There could be several explanations for these results. We propose two key hypotheses:

1) Changes in the examination procedure in 2020. Since official exams were canceled that year, schools in the region conducted exams independently, relying solely on their internal resources to monitor students during the exams. It is highly likely that schools with low SES were not as strict in monitoring students as schools with high SES.

2) Different durations of distance learning in schools with high and low SES. According to regional legislative directives, schools in municipalities with a small population (often with low SES schools) returned to in-person learning earlier in 2020 than larger schools. It is likely that due to less time spent in distance learning, the impact of the pandemic was less pronounced in these schools.

The second hypothesis is of particular interest. If confirmed, it may suggest that distance learning had a negative impact even on well-off Russian schools, where there was sufficient technical capacity to organize the process effectively. Currently, we are gathering additional data from the region to test this assumption. So, in the near future, we will attempt to provide a more precise explanation of the identified trends and present new findings.